{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be647ef-2495-42ee-afbc-51433fe3c535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchviz import make_dot\n",
    "\n",
    "# 定义一个多项式函数\n",
    "class PolynomialModel(nn.Module):\n",
    "    def __init__(self, degree):\n",
    "        super(PolynomialModel, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.layers = nn.ModuleList([nn.Linear(1, 1, bias=False) for _ in range(degree + 1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算多项式\n",
    "        out = torch.zeros_like(x)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            out += layer(x) * x**i\n",
    "        return out\n",
    "\n",
    "# 初始化模型\n",
    "degree = 3  # 多项式的最高次数\n",
    "model = PolynomialModel(degree)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 生成一些随机数据来模拟x和y的关系\n",
    "x_data = torch.randn(100, 1)  # 生成100个随机样本\n",
    "y_data = torch.cat([x_data**i for i in range(degree + 1)], 1).sum(1, keepdim=True)  # 计算y的理论值\n",
    "\n",
    "# 添加随机噪声来模拟真实数据\n",
    "y_data += torch.randn_like(y_data) * 0.1  # 假设噪声是均值为0，标准差为0.1的正态分布\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    # 生成随时间变化的随机变量 τ(t)\n",
    "    tau = torch.randn_like(x_data)  # 假设 x_data 已经被定义，并且具有正确的时间维度\n",
    "    \n",
    "    # 计算模型的输出\n",
    "    y_pred = model(x_data) + tau  # 将随机变量添加到模型的输出中\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# 可视化模型\n",
    "x_test = torch.linspace(-3, 3, 100).unsqueeze(1)  # 创建一个测试集\n",
    "y_pred = model(x_test)\n",
    "\n",
    "plt.scatter(x_data.numpy(), y_data.numpy(), color='blue', label='Data Points')\n",
    "plt.plot(x_test.numpy(), y_pred.detach().numpy(), color='red', label='Polynomial Fit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c054764-7613-4172-934a-b39e5df57e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0aec48-fc21-4384-b918-6e94ccc3fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义一个多项式函数\n",
    "class PolynomialModel(nn.Module):\n",
    "    def __init__(self, degree):\n",
    "        super(PolynomialModel, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.layers = nn.ModuleList([nn.Linear(1, 1, bias=False) for _ in range(degree + 1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 计算多项式\n",
    "        out = torch.zeros_like(x)\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            out += layer(x) * x**i\n",
    "        return out\n",
    "\n",
    "# 初始化模型\n",
    "degree = 3  # 多项式的最高次数\n",
    "model = PolynomialModel(degree)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 生成随时间变化的随机变量 τ(t)\n",
    "    tau = torch.randn_like(x_data)  # 假设 x_data 已经被定义，并且具有正确的时间维度\n",
    "    \n",
    "    # 计算模型的输出\n",
    "    y_pred = model(x_data) + tau  # 将随机变量添加到模型的输出中\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce45299-2745-4ef4-afea-c1c98d3d9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from power_plant_dataset import PowerPlantDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "dataset = PowerPlantDataset(csv_file='fdcl/split/df_hdrm.csv')\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "rou_train = 1.2\n",
    "rou_test = 1.3\n",
    "\n",
    "# 定义一个简单的多项式函数\n",
    "class PolynomialRegressor(nn.Module):\n",
    "    def __init__(self, degree):\n",
    "        super(PolynomialRegressor, self).__init__()\n",
    "        self.degree = degree\n",
    "        self.coefficients = nn.Parameter(torch.randn(degree + 1))  # 随机初始化系数\n",
    "\n",
    "    def forward(self, x, rou):\n",
    "        # 计算多项式的值\n",
    "        out = torch.sum(self.coefficients * x * rou, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f518c8-dd8b-448f-a62f-4704509b1ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_features, batch_labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m---> 14\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrou_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 使用训练集的随机变量参数\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, batch_labels)\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/sql/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sql/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m, in \u001b[0;36mPolynomialRegressor.forward\u001b[0;34m(self, x, rou)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, rou):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 计算多项式的值\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrou\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "degree = 3  # 多项式的最高次数\n",
    "model = PolynomialRegressor(degree)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    for batch_features, batch_labels in dataloader:\n",
    "        y_pred = model(-0.5, rou_train)  # 使用训练集的随机变量参数\n",
    "        loss = criterion(y_pred, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# 使用测试集测试模型\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in dataloader:\n",
    "        y_pred = model(batch_features, rou_test)  # 使用测试集的随机变量参数\n",
    "        print(f'Test Loss: {criterion(y_pred, batch_labels).item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
